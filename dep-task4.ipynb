{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30746,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torchvision\nimport torchvision.transforms as transforms\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport torch.nn.functional as F\n\n# Hyperparameters\nbatch_size = 128\nlearning_rate = 0.001\nnum_epochs = 10\n\n# Data augmentation and preprocessing\ntransform_train = transforms.Compose([\n    transforms.RandomHorizontalFlip(),\n    transforms.ToTensor(),\n    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n])\n\ntransform_test = transforms.Compose([\n    transforms.ToTensor(),\n    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n])\n\n# CIFAR-10 dataset\ntrain_dataset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)\ntest_dataset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)\n\ntrain_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\ntest_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n\n# Define a simple CNN model\nclass SimpleCNN(nn.Module):\n    def __init__(self):\n        super(SimpleCNN, self).__init__()\n        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n        self.fc1 = nn.Linear(64 * 8 * 8, 256)\n        self.fc2 = nn.Linear(256, 10)\n\n    def forward(self, x):\n        x = self.pool(F.relu(self.conv1(x)))\n        x = self.pool(F.relu(self.conv2(x)))\n        x = x.view(-1, 64 * 8 * 8)\n        x = F.relu(self.fc1(x))\n        x = self.fc2(x)\n        return x\n\n# Model, loss function, and optimizer\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nmodel = SimpleCNN().to(device)\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr=learning_rate)\n\n# Training the model\ndef train(model, train_loader, criterion, optimizer, epoch):\n    model.train()\n    running_loss = 0.0\n    correct = 0\n    total = 0\n    for i, (inputs, labels) in enumerate(train_loader):\n        inputs, labels = inputs.to(device), labels.to(device)\n        optimizer.zero_grad()\n        outputs = model(inputs)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n\n        running_loss += loss.item()\n        _, predicted = outputs.max(1)\n        total += labels.size(0)\n        correct += predicted.eq(labels).sum().item()\n\n        if i % 100 == 99:  # Print every 100 batches\n            print(f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{len(train_loader)}], Loss: {running_loss/100:.4f}, Accuracy: {100*correct/total:.2f}%')\n            running_loss = 0.0\n\n# Evaluating the model\ndef test(model, test_loader):\n    model.eval()\n    correct = 0\n    total = 0\n    with torch.no_grad():\n        for inputs, labels in test_loader:\n            inputs, labels = inputs.to(device), labels.to(device)\n            outputs = model(inputs)\n            _, predicted = outputs.max(1)\n            total += labels.size(0)\n            correct += predicted.eq(labels).sum().item()\n\n    print(f'Test Accuracy: {100*correct/total:.2f}%')\n    return 100 * correct / total\n\n# Training and evaluation loop\nbest_accuracy = 0\nfor epoch in range(num_epochs):\n    train(model, train_loader, criterion, optimizer, epoch)\n    accuracy = test(model, test_loader)\n    if accuracy > best_accuracy:\n        best_accuracy = accuracy\n        torch.save(model.state_dict(), 'best_model.pth')\n\nprint(f'Best Test Accuracy: {best_accuracy:.2f}%')\n\n# Plot some test images with predictions\ndef imshow(img):\n    img = img / 2 + 0.5  # unnormalize\n    npimg = img.numpy()\n    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n    plt.show()\n\n# Get some random test images\ndataiter = iter(test_loader)\nimages, labels = dataiter.next()\n\n# Print images\nimshow(torchvision.utils.make_grid(images))\noutputs = model(images.to(device))\n_, predicted = outputs.max(1)\n\n# Print predicted labels\nprint('Predicted: ', ' '.join(f'{train_dataset.classes[predicted[j]]}' for j in range(4)))\n\n# Print actual labels\nprint('GroundTruth: ', ' '.join(f'{train_dataset.classes[labels[j]]}' for j in range(4)))\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-07-27T02:07:42.081284Z","iopub.execute_input":"2024-07-27T02:07:42.081988Z","iopub.status.idle":"2024-07-27T02:16:12.329655Z","shell.execute_reply.started":"2024-07-27T02:07:42.081935Z","shell.execute_reply":"2024-07-27T02:16:12.327907Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Requirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (2.1.2+cpu)\nRequirement already satisfied: torchvision in /opt/conda/lib/python3.10/site-packages (0.16.2+cpu)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch) (3.13.1)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch) (4.9.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch) (1.13.0)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch) (3.1.2)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch) (2024.5.0)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from torchvision) (1.26.4)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from torchvision) (2.32.3)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.10/site-packages (from torchvision) (9.5.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch) (2.1.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision) (2024.7.4)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\nFiles already downloaded and verified\nFiles already downloaded and verified\nEpoch [1/10], Step [100/391], Loss: 1.6993, Accuracy: 38.97%\nEpoch [1/10], Step [200/391], Loss: 1.3814, Accuracy: 44.66%\nEpoch [1/10], Step [300/391], Loss: 1.2454, Accuracy: 48.32%\nTest Accuracy: 59.30%\nEpoch [2/10], Step [100/391], Loss: 1.0703, Accuracy: 61.90%\nEpoch [2/10], Step [200/391], Loss: 1.0380, Accuracy: 62.85%\nEpoch [2/10], Step [300/391], Loss: 0.9977, Accuracy: 63.34%\nTest Accuracy: 67.03%\nEpoch [3/10], Step [100/391], Loss: 0.9009, Accuracy: 67.91%\nEpoch [3/10], Step [200/391], Loss: 0.8898, Accuracy: 68.36%\nEpoch [3/10], Step [300/391], Loss: 0.8618, Accuracy: 68.82%\nTest Accuracy: 69.09%\nEpoch [4/10], Step [100/391], Loss: 0.7920, Accuracy: 71.46%\nEpoch [4/10], Step [200/391], Loss: 0.7621, Accuracy: 72.56%\nEpoch [4/10], Step [300/391], Loss: 0.7769, Accuracy: 72.61%\nTest Accuracy: 72.00%\nEpoch [5/10], Step [100/391], Loss: 0.6969, Accuracy: 75.55%\nEpoch [5/10], Step [200/391], Loss: 0.7100, Accuracy: 75.48%\nEpoch [5/10], Step [300/391], Loss: 0.6995, Accuracy: 75.47%\nTest Accuracy: 71.72%\nEpoch [6/10], Step [100/391], Loss: 0.6287, Accuracy: 78.08%\nEpoch [6/10], Step [200/391], Loss: 0.6242, Accuracy: 78.05%\nEpoch [6/10], Step [300/391], Loss: 0.6179, Accuracy: 78.17%\nTest Accuracy: 72.40%\nEpoch [7/10], Step [100/391], Loss: 0.5600, Accuracy: 79.98%\nEpoch [7/10], Step [200/391], Loss: 0.5678, Accuracy: 80.21%\nEpoch [7/10], Step [300/391], Loss: 0.5582, Accuracy: 80.24%\nTest Accuracy: 73.98%\nEpoch [8/10], Step [100/391], Loss: 0.5061, Accuracy: 82.59%\nEpoch [8/10], Step [200/391], Loss: 0.5037, Accuracy: 82.54%\nEpoch [8/10], Step [300/391], Loss: 0.5133, Accuracy: 82.39%\nTest Accuracy: 74.74%\nEpoch [9/10], Step [100/391], Loss: 0.4555, Accuracy: 84.34%\nEpoch [9/10], Step [200/391], Loss: 0.4453, Accuracy: 84.64%\nEpoch [9/10], Step [300/391], Loss: 0.4532, Accuracy: 84.48%\nTest Accuracy: 75.16%\nEpoch [10/10], Step [100/391], Loss: 0.3880, Accuracy: 86.66%\nEpoch [10/10], Step [200/391], Loss: 0.4097, Accuracy: 86.33%\nEpoch [10/10], Step [300/391], Loss: 0.3985, Accuracy: 86.27%\nTest Accuracy: 75.59%\nBest Test Accuracy: 75.59%\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","Cell \u001b[0;32mIn[3], line 120\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;66;03m# Get some random test images\u001b[39;00m\n\u001b[1;32m    119\u001b[0m dataiter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28miter\u001b[39m(test_loader)\n\u001b[0;32m--> 120\u001b[0m images, labels \u001b[38;5;241m=\u001b[39m \u001b[43mdataiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnext\u001b[49m()\n\u001b[1;32m    122\u001b[0m \u001b[38;5;66;03m# Print images\u001b[39;00m\n\u001b[1;32m    123\u001b[0m imshow(torchvision\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mmake_grid(images))\n","\u001b[0;31mAttributeError\u001b[0m: '_MultiProcessingDataLoaderIter' object has no attribute 'next'"],"ename":"AttributeError","evalue":"'_MultiProcessingDataLoaderIter' object has no attribute 'next'","output_type":"error"}]}]}